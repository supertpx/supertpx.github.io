<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[字符在字符串中出现的频率统计]]></title>
    <url>%2Fac-1%2F</url>
    <content type="text"><![CDATA[问题描述： 统计字符串中每一个字符在该字符串中出现的次数，按次数从高至低排序输出，若次数相同，则按在该字符串中出现的顺序输出，区分大小写。 解题思路： 此题分为两部分，统计字符出现次数，可以用LinkedHashMap来统计；按次数从高至低输出，则需要对map的value进行排序，可以利用Comparator比较器。 具体实现代码如下： testAC1.java123456789101112131415161718192021222324252627282930313233343536373839import java.util.ArrayList;import java.util.Collections;import java.util.Comparator;import java.util.LinkedHashMap;import java.util.List;import java.util.Map;import java.util.Map.Entry;import java.util.Scanner;public class testAC1 &#123; public static void main(String[] Args) &#123; Scanner sc = new Scanner(System.in); while (sc.hasNextLine()) &#123; String str = sc.nextLine(); Map&lt;Character, Integer&gt; map = new LinkedHashMap&lt;Character, Integer&gt;(); // 利用map统计字符出现次数 for (int i = 0; i &lt; str.length(); i++) &#123; char ch = str.charAt(i); if (map.containsKey(ch)) &#123; map.put(ch, map.get(ch) + 1); &#125; else &#123; map.put(ch, 1); &#125; &#125; // 用Comparator比较器排序 List&lt;Map.Entry&lt;Character, Integer&gt;&gt; list = new ArrayList&lt;Map.Entry&lt;Character, Integer&gt;&gt;(map.entrySet()); Collections.sort(list, new Comparator&lt;Map.Entry&lt;Character, Integer&gt;&gt;() &#123; @Override public int compare(Entry&lt;Character, Integer&gt; o1, Entry&lt;Character, Integer&gt; o2) &#123; return o2.getValue().compareTo(o1.getValue()); &#125; &#125;); for (Map.Entry&lt;Character, Integer&gt; m : list) &#123; System.out.println(m.getKey() + "=" + m.getValue()); &#125; &#125; sc.close(); &#125;&#125;]]></content>
      <categories>
        <category>AC</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[服务治理组件Eureka]]></title>
    <url>%2Fabout-Eureka%2F</url>
    <content type="text"><![CDATA[Eurka是由Netflix开发的一套具有服务治理功能的组件，Spring Cloud在其基础上进行了二次封装，将其融入到了Spring Cloud微服务体系中。服务治理在任何一个微服务框架中都应是一个基础且重要的功能。 Eureka的服务端和客户端Eureka主要有两个重要的组成部分：Eureka Server和Eureka Client。顾名思义，Eureka Server，又称服务注册中心，其维护了一个ConcurrentHashMap对象registry，为一个双层map结构（ConcurrentHashMap&lt;String, Map&lt;String, Lease&gt;&gt;），registry外层的key为服务实例Instance注册时提供的AppName，内层的key为该Instance的Id。通过该对象，Eureka Server可以对外提供一个按服务名（AppName）分类组织的服务清单，该清单会通过心跳检测的机制去更新。Eureka Client提供了两个重要的功能：服务获取和服务注册（续约）。其中，服务获取可用于服务消费者，服务注册（续约）可用于服务提供者。 Eureka Server在一个基础的Spring Boot项目中，在pom.xml文件导入以下依赖： pom.xml1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 然后在该应用的主类中加上@EnableEurekaServer注解，即可开启一个Eureka Server。如果需要对端口等行为进行自定义，可以在application.properties中配置如下： application.properties12345678spring.application.name=eureka-serverserver.port=1001eureka.instance.hostname=peer#eureka.client.register-with-eureka=false#eureka.client.fetch-registry=falseeureka.server.renewalPercentThreshold=0.49eureka.client.serviceUrl.defaultZone=http://peer1:1002/eureka/ 其中eureka.client.serviceUrl.defaultZone一般为本机hostname+端口+/eureka/，本机已搭建了一个高可用的Eureka Server集群，分别有peer和peer1两个节点，两个节点的defaultZone互为对方地址。启动这两个节点，访问http://peer1:1002/eureka/ 或者 http://peer:1001/eureka/ ，可以见到如下界面： 图中可以看出，本机已启动了两个Eureka Server节点，两个Eureka Client节点，以及一个服务消费者节点。先看Eureka Server节点。打开spring-cloud-netflix-eureka的jar包（以2.1.1版本为例），我们可以看到如下的目录结构： 可以看到Eureka Server定义了5个事件，其中三个与Eureka Client相关，分别是EurekaInstanceCanceledEvent（服务的取消）、EurekaInstanceRegisteredEvent（服务的注册）、EurekaInstanceRenewedEvent（服务的续约），EurekaRegistryAvailableEvent和EurekaServerStartedEvent则与Eureka Server自身启动和注册相关。 查看InstanceRegistry类，可以找到跟服务注册、取消、续约相关的代码片段如下： InstanceRegistry.class12345678910111213141516171819202122232425262728293031323334@Overridepublic void register(InstanceInfo info, int leaseDuration, boolean isReplication) &#123; handleRegistration(info, leaseDuration, isReplication); super.register(info, leaseDuration, isReplication);&#125;@Overridepublic boolean cancel(String appName, String serverId, boolean isReplication) &#123; handleCancelation(appName, serverId, isReplication); return super.cancel(appName, serverId, isReplication);&#125;@Overridepublic boolean renew(final String appName, final String serverId, boolean isReplication) &#123; log("renew " + appName + " serverId " + serverId + ", isReplication &#123;&#125;" + isReplication); List&lt;Application&gt; applications = getSortedApplications(); for (Application input : applications) &#123; if (input.getName().equals(appName)) &#123; InstanceInfo instance = null; for (InstanceInfo info : input.getInstances()) &#123; if (info.getId().equals(serverId)) &#123; instance = info; break; &#125; &#125; publishEvent(new EurekaInstanceRenewedEvent(this, appName, serverId, instance, isReplication)); break; &#125; &#125; return super.renew(appName, serverId, isReplication);&#125; 其中，服务注册和取消的时候，都会先通过Spring Context发布一个事件，通知网络中的其他Eureka Server节点，然后再执行相应的注册或取消动作。服务续约则会从已存储的服务列表中找到appName与serverId一致的那个服务实例，发布续约事件，然后执行续约动作。以注册动作为例，根据super.register(info, leaseDuration, isReplication)找到eureka-core包中的AbstractInstanceRegistry类，可以看到register动作的函数体为： AbstractInstanceRegistry.class123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public void register(InstanceInfo registrant, int leaseDuration, boolean isReplication) &#123; try &#123; read.lock(); Map&lt;String, Lease&lt;InstanceInfo&gt;&gt; gMap = registry.get(registrant.getAppName()); REGISTER.increment(isReplication); if (gMap == null) &#123; final ConcurrentHashMap&lt;String, Lease&lt;InstanceInfo&gt;&gt; gNewMap = new ConcurrentHashMap&lt;String, Lease&lt;InstanceInfo&gt;&gt;(); gMap = registry.putIfAbsent(registrant.getAppName(), gNewMap); if (gMap == null) &#123; gMap = gNewMap; &#125; &#125; Lease&lt;InstanceInfo&gt; existingLease = gMap.get(registrant.getId()); // Retain the last dirty timestamp without overwriting it, if there is already a lease if (existingLease != null &amp;&amp; (existingLease.getHolder() != null)) &#123; ... // this is a &gt; instead of a &gt;= because if the timestamps are equal, we still take the remote transmitted // InstanceInfo instead of the server local copy. ... &#125; else &#123; // The lease does not exist and hence it is a new registration synchronized (lock) &#123; if (this.expectedNumberOfClientsSendingRenews &gt; 0) &#123; // Since the client wants to register it, increase the number of clients sending renews this.expectedNumberOfClientsSendingRenews = this.expectedNumberOfClientsSendingRenews + 1; updateRenewsPerMinThreshold(); &#125; &#125; logger.debug("No previous lease information found; it is new registration"); &#125; Lease&lt;InstanceInfo&gt; lease = new Lease&lt;InstanceInfo&gt;(registrant, leaseDuration); if (existingLease != null) &#123; lease.setServiceUpTimestamp(existingLease.getServiceUpTimestamp()); &#125; gMap.put(registrant.getId(), lease); synchronized (recentRegisteredQueue) &#123; recentRegisteredQueue.add(new Pair&lt;Long, String&gt;( System.currentTimeMillis(), registrant.getAppName() + "(" + registrant.getId() + ")")); &#125; // This is where the initial state transfer of overridden status happens ... // If the lease is registered with UP status, set lease service up timestamp if (InstanceStatus.UP.equals(registrant.getStatus())) &#123; lease.serviceUp(); &#125; registrant.setActionType(ActionType.ADDED); recentlyChangedQueue.add(new RecentlyChangedItem(lease)); ... &#125; finally &#123; read.unlock(); &#125;&#125; 该函数中，Eureka Server维护了一个上文中提到的ConcurrentHashMap对象registry，以及recentRegisteredQueue和recentlyChangedQueue两个序列。在register动作发生时，Eureka Server首先会去检查registry对象，查看需要注册的InstanceInfo是否存在，如果存在，则修改对应的状态、时间等相关信息；如果不存在，则增加，并在recentRegisteredQueue和recentlyChangedQueue中登记。 服务取消动作和续约动作分别对应该类中的internalCancel和renew函数。 Eureka Client在微服务体系中，除去Eureka Server之外的服务，都具有Eureka Client的属性，因为它们要么是服务提供者，要么是服务消费者，或者两者都是。 服务提供者在pom.xml中导入以下依赖： pom.xml1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 并在应用主类中添加@EnableDiscoveryClient注解，即可开启一个Eureka Client。如果需要对端口等行为进行自定义，可以在application.properties中配置如下： application.properties123456spring.application.name=eureka-clientserver.port=2001eureka.client.serviceUrl.defaultZone=http://peer:1001/eureka/,http://peer1:1002/eureka/#eureka.client.healthcheck.enabled=true#eureka.instance.statusPageUrlPath=http://localhost:1001/info#eureka.instance.healthCheckUrlPath=http://localhost:1001/health 作为服务提供者，则需要提供接口供服务消费者来消费。本例中以rest请求的方式定义一个最简单的接口，示例如下： EcController.java12345678910111213141516171819package com.tpx.ms.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.cloud.client.discovery.DiscoveryClient;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class EcController &#123; @Autowired private DiscoveryClient discoveryClient; @GetMapping("/dc") public String dc() &#123; String services = "Services: " + discoveryClient.getServices(); System.out.println(services); return services; &#125;&#125; 通过注入DiscoveryClient对象，可以得到这个Eureka Client的相关信息。打开spring-cloud-netflix-eureka-client的jar包，可以看到如下的目录结构： 图中可以看到spring-cloud-netflix-eureka-client只是Spring Cloud的封装，图下的位置里还有一个eureka-client的jar包。查看DiscoveryClient类的构造方法，代码如下： DiscoveryClient.class123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101@InjectDiscoveryClient(ApplicationInfoManager applicationInfoManager, EurekaClientConfig config, AbstractDiscoveryClientOptionalArgs args, Provider&lt;BackupRegistry&gt; backupRegistryProvider) &#123; ... if (config.shouldFetchRegistry()) &#123; this.registryStalenessMonitor = new ThresholdLevelsMetric(this, METRIC_REGISTRY_PREFIX + "lastUpdateSec_", new long[]&#123;15L, 30L, 60L, 120L, 240L, 480L&#125;); &#125; else &#123; this.registryStalenessMonitor = ThresholdLevelsMetric.NO_OP_METRIC; &#125; if (config.shouldRegisterWithEureka()) &#123; this.heartbeatStalenessMonitor = new ThresholdLevelsMetric(this, METRIC_REGISTRATION_PREFIX + "lastHeartbeatSec_", new long[]&#123;15L, 30L, 60L, 120L, 240L, 480L&#125;); &#125; else &#123; this.heartbeatStalenessMonitor = ThresholdLevelsMetric.NO_OP_METRIC; &#125; logger.info("Initializing Eureka in region &#123;&#125;", clientConfig.getRegion()); if (!config.shouldRegisterWithEureka() &amp;&amp; !config.shouldFetchRegistry()) &#123; logger.info("Client configured to neither register nor query for data."); scheduler = null; heartbeatExecutor = null; cacheRefreshExecutor = null; eurekaTransport = null; instanceRegionChecker = new InstanceRegionChecker(new PropertyBasedAzToRegionMapper(config), clientConfig.getRegion()); // This is a bit of hack to allow for existing code using DiscoveryManager.getInstance() // to work with DI'd DiscoveryClient DiscoveryManager.getInstance().setDiscoveryClient(this); DiscoveryManager.getInstance().setEurekaClientConfig(config); initTimestampMs = System.currentTimeMillis(); logger.info("Discovery Client initialized at timestamp &#123;&#125; with initial instances count: &#123;&#125;", initTimestampMs, this.getApplications().size()); return; // no need to setup up an network tasks and we are done &#125; try &#123; // default size of 2 - 1 each for heartbeat and cacheRefresh scheduler = Executors.newScheduledThreadPool(2, new ThreadFactoryBuilder() .setNameFormat("DiscoveryClient-%d") .setDaemon(true) .build()); heartbeatExecutor = new ThreadPoolExecutor( 1, clientConfig.getHeartbeatExecutorThreadPoolSize(), 0, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), new ThreadFactoryBuilder() .setNameFormat("DiscoveryClient-HeartbeatExecutor-%d") .setDaemon(true) .build() ); // use direct handoff cacheRefreshExecutor = new ThreadPoolExecutor( 1, clientConfig.getCacheRefreshExecutorThreadPoolSize(), 0, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), new ThreadFactoryBuilder() .setNameFormat("DiscoveryClient-CacheRefreshExecutor-%d") .setDaemon(true) .build() ); // use direct handoff eurekaTransport = new EurekaTransport(); scheduleServerEndpointTask(eurekaTransport, args); ... &#125; catch (Throwable e) &#123; throw new RuntimeException("Failed to initialize DiscoveryClient!", e); &#125; if (clientConfig.shouldFetchRegistry() &amp;&amp; !fetchRegistry(false)) &#123; fetchRegistryFromBackup(); &#125; // call and execute the pre registration handler before all background tasks (inc registration) is started if (this.preRegistrationHandler != null) &#123; this.preRegistrationHandler.beforeRegistration(); &#125; if (clientConfig.shouldRegisterWithEureka() &amp;&amp; clientConfig.shouldEnforceRegistrationAtInit()) &#123; try &#123; if (!register() ) &#123; throw new IllegalStateException("Registration error at startup. Invalid server response."); &#125; &#125; catch (Throwable th) &#123; logger.error("Registration error at startup: &#123;&#125;", th.getMessage()); throw new IllegalStateException(th); &#125; &#125; // finally, init the schedule tasks (e.g. cluster resolvers, heartbeat, instanceInfo replicator, fetch initScheduledTasks(); ...&#125; 代码有部分精简，从这个函数可以看出，在Eureka Client初始化的过程中，会先对一系列参数进行检查，其中最重要的两个参数为fetchRegistry和registerWithEureka，默认为ture。参数检查完毕之后，会执行scheduleServerEndpointTask函数，该方法会根据参数给EurekaTransport对象赋值，用于传输到Eureka Server端；然后执行initScheduledTasks函数，部分代码如下： DiscoveryClient.class12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364private void initScheduledTasks() &#123; if (clientConfig.shouldFetchRegistry()) &#123; // registry cache refresh timer int registryFetchIntervalSeconds = clientConfig.getRegistryFetchIntervalSeconds(); int expBackOffBound = clientConfig.getCacheRefreshExecutorExponentialBackOffBound(); scheduler.schedule( new TimedSupervisorTask( "cacheRefresh", scheduler, cacheRefreshExecutor, registryFetchIntervalSeconds, TimeUnit.SECONDS, expBackOffBound, new CacheRefreshThread() ), registryFetchIntervalSeconds, TimeUnit.SECONDS); &#125; if (clientConfig.shouldRegisterWithEureka()) &#123; int renewalIntervalInSecs = instanceInfo.getLeaseInfo().getRenewalIntervalInSecs(); int expBackOffBound = clientConfig.getHeartbeatExecutorExponentialBackOffBound(); logger.info("Starting heartbeat executor: " + "renew interval is: &#123;&#125;", renewalIntervalInSecs); // Heartbeat timer scheduler.schedule( new TimedSupervisorTask( "heartbeat", scheduler, heartbeatExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, expBackOffBound, new HeartbeatThread() ), renewalIntervalInSecs, TimeUnit.SECONDS); // InstanceInfo replicator instanceInfoReplicator = new InstanceInfoReplicator( this, instanceInfo, clientConfig.getInstanceInfoReplicationIntervalSeconds(), 2); // burstSize statusChangeListener = new ApplicationInfoManager.StatusChangeListener() &#123; @Override public String getId() &#123; return "statusChangeListener"; &#125; @Override public void notify(StatusChangeEvent statusChangeEvent) &#123; ... &#125; &#125;; ... &#125; else &#123; logger.info("Not registering with Eureka server per configuration"); &#125;&#125; 该函数中有两个重要的if分支，按顺序分别对应服务获取、服务注册（续约）功能，需要注意的是，服务获取只有cacheRefresh这个定时任务，而服务注册（续约）则拥有heartbeat定时任务、InstanceInfoReplicator、StatusChangeListener等功能。在InstanceInfoReplicator实例中，有一个定时任务会执行register函数，该函数的作用是将client自身的instanceinfo以rest请求的方式发送给Server端，从而完成注册。heartbeat定时任务则利用心跳机制来进行服务续约。 服务消费者新建服务提供者的步骤也可用于新建服务消费者，不同的是，我们需要消费服务提供者提供的dc接口。在Spring Boot项目中定义一个interface用于访问dc接口，代码如下： Finterface.java12345678910package com.tpx.ms.restinterface;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.GetMapping;@FeignClient("eureka-client")public interface Finterface &#123; @GetMapping("/dc") String consumer();&#125; 然后再定义一个Controller用于调用该interface，代码如下: FController.java1234567891011121314151617package com.tpx.ms.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class FController &#123; @Autowired com.tpx.ms.restinterface.Finterface Finterface; @GetMapping("/consumer") public String dc() &#123; return Finterface.consumer(); &#125;&#125; 经过以上对服务提供者的分析，可以得知，严格意义上的服务消费者，其实只需要开启服务获取的功能即可。在initScheduledTasks函数中，第一个服务获取的if分支中提供了一个cacheRefresh的定时任务，该任务会定时获取Eureka Server端的服务提供者列表，存储在本地并定期刷新。通过这个机制，我们可以实现客户端负载均衡。 其他 更多关于Eureka Server和Eureka Client的配置相关信息，可以查看EurekaServerConfigBean和EurekaClientConfigBean的源码； Eureka Client配置时，还有关于Region和Zone的配置，本文不再展开； 各节点的/info和/heath信息需配合spring-boot-starter-actuator使用。]]></content>
      <categories>
        <category>框架</category>
        <category>微服务-Spring Cloud</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[JVM内存模型]]></title>
    <url>%2Fabout-jvm%2F</url>
    <content type="text"><![CDATA[JVM中的五种内存区块及其作用 JVM内存模型jvm内存模型图： 从上图中可以看到，JVM在运行时内存模型中总共可分为五个区块：程序计数器（PC Register）、虚拟机栈（JVM stack）、本地方法栈（native method stack）、堆（heap）、方法区（method area），其中方法区里还包含运行时常量池（runtime constant pool）。程序计数器、虚拟机栈、本地方法栈这三者是线程私有的，而堆是线程公有的。 程序计数器程序计数器是最小的一块内存区域，它的作用是当前线程所执行的字节码的行号指示器，在虚拟机的模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、异常处理、线程恢复等基础功能都需要依赖计数器完成。程序计数器是唯一一块不存在OutOfMemoryError异常的区域。 虚拟机栈虚拟机栈由线程私有，由此可知这块内存区域存有跟方法运行时相关的一些私有变量（局部变量）。每个方法被执行的时候都会创建一个”栈帧”,用于存储局部变量表(包括参数)、操作栈、方法出口等信息。每个方法被调用到执行完的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。声明周期与线程相同，是线程私有的。栈帧由三部分组成：局部变量区、操作数栈、帧数据区。局部变量区被组织为以一个字长为单位、从0开始计数的数组，和局部变量区一样，操作数栈也被组织成一个以字长为单位的数组。但和前者不同的是，它不是通过索引来访问的，而是通过入栈和出栈来访问的，可以看作为临时数据的存储区域。除了局部变量区和操作数栈外，java栈帧还需要一些数据来支持常量池解析、正常方法返回以及异常派发机制。这些数据都保存在java栈帧的帧数据区中。该区可以抛出StackOverflowError或OutOfMemoryError异常。 本地方法栈与虚拟机栈基本类似，区别在于虚拟机栈为虚拟机执行的java方法服务，而本地方法栈则是为Native方法服务。 堆是java虚拟机所管理的内存中最大的一块内存区域，该内存区域存放了对象实例及数组（但不是所有的对象实例都在堆中）。其大小通过-Xms(最小值)和-Xmx(最大值)参数设置（最大最小值都要小于1G），前者为启动时申请的最小内存，默认为操作系统物理内存的1/64，后者为JVM可申请的最大内存,默认为物理内存的1/4，默认当空余堆内存小于40%时，JVM会增大堆内存到-Xmx指定的大小，可通过-XX:MinHeapFreeRation=来指定这个比列；当空余堆内存大于70%时，JVM会减小堆内存的大小到-Xms指定的大小，可通过XX:MaxHeapFreeRation=来指定这个比列，当然为了避免在运行时频繁调整Heap的大小，通常-Xms与-Xmx的值设成一样。该区可以抛出OutOfMemoryError异常。 堆内存 = 新生代+老生代+持久代。在我们垃圾回收的时候，我们往往将堆内存分成新生代和老生代（大小比例1：2），新生代中由Eden和Survivor0，Survivor1组成，三者的比例是8：1：1，新生代的回收机制采用复制算法，在Minor GC的时候，我们都留一个存活区用来存放存活的对象，真正进行的区域是Eden+其中一个存活区，当我们的对象时长超过一定年龄时（默认15，可以通过参数设置），将会把对象放入老生代，当然大的对象会直接进入老生代。老生代采用的回收算法是标记整理算法。 方法区方法区也称”永久代”，它用于存储虚拟机加载的类信息、常量、静态变量。默认最小值为16MB，最大值为64MB（64位JVM由于指针膨胀，默认是85M），可以通过-XX:PermSize 和 -XX:MaxPermSize 参数限制方法区的大小。它是一片连续的堆空间，永久代的垃圾收集是和老年代(old generation)捆绑在一起的，因此无论谁满了，都会触发永久代和老年代的垃圾收集。该区可以抛出OutOfMemoryError异常。 运行时常量池：是方法区的一部分，Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译器生成的各种符号引用，这部分内容将在类加载后放到方法区的运行时常量池中。 参考文献 JVM内存模型与垃圾回收 深入理解java虚拟机]]></content>
      <categories>
        <category>基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数据库连接池的一些理解]]></title>
    <url>%2Fabout-sql-connection-pool%2F</url>
    <content type="text"><![CDATA[数据库连接池的作用及其原理 数据库连接池的作用对于复杂业务场景下的应用，会需要频繁访问数据库资源。在这种场景下，频繁的建立、关闭数据库连接会对系统的性能照成极大的影响。为了解决这个性能瓶颈，可以考虑实现对数据库资源–连接的复用。对于数据库这类共享资源，有一个经典的设计模式：资源池。将资源池的设计理念引入数据库连接管理层面，就得到了数据库连接池。数据库连接池的目的是为了提供一套高效的连接分配、使用策略，最终目标是实现连接的高效、安全的复用。其基本原理是在内部对象池中维护一定数量的数据库连接，并对外暴露数据库连接获取和返回方法。 数据库连接池的工作原理首先要说明一个问题，频繁建立、关闭数据库连接为什么会消耗更多的系统资源。原因在于，数据库连接建立时，会经历TCP的三握四挥，还有数据库的认证，最后才是真正的sql执行过程。其中TCP连接和数据库认证是业务上不需要关心的，在此基础上，才可以考虑连接的复用。 数据库连接池的功能主要有三个部分： 连接池的建立；在系统初始化时，依照系统配置来创建连接池，并在池中建立几个连接对象，以便使用时获取。连接池中的连接不允许随意建立和关闭，避免系统开销。 连接的使用和管理；当客户请求数据库连接时，首先查看连接池中是否有空闲连接，如果存在空闲连接，则将连接分配给客户使用；如果没有空闲连接，则查看当前所开的连接数是否已经达到最大连接数，如果没达到就重新创建一个连接给请求的客户；如果达到就按设定的最大等待时间进行等待，如果超出最大等待时间，则抛出异常给客户。当客户释放数据库连接时，先判断该连接的引用次数是否超过了规定值，如果超过就从连接池中删除该连接，否则保留为其他客户服务。 连接池的关闭；当系统或者应用关闭时，关闭连接池，释放所有连接。 数据库连接connection与statement、resultset之间的关系 连接池主要参数 最小连接数：是连接池一直保持的数据库连接，所以如果应用程序对数据库连接的使用量不大，将会有大量的数据库连接资源被浪费； 最大连接数：是连接池能申请的最大连接数，如果数据库连接请求超过次数，后面的数据库连接请求将被加入到等待队列中，这会影响以后的数据库操作； 最大空闲时间； 获取连接超时时间； 超时重试连接次数。 使用连接池需要注意的问题 并发问题，使用synchronized关键字； 事务处理，采用单个连接使用独占事务的模式等策略； 连接池管理，如连接的分配与释放，配置与维护等； 连接池的选择HikariCP、Druid等开源连接池。]]></content>
      <categories>
        <category>基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[关于TCP/IP协议]]></title>
    <url>%2Fabout-tcp-ip%2F</url>
    <content type="text"><![CDATA[TCP/IP协议详解，两个重点：协议的层次，client和server之间的三握四挥 TCP/IP协议模型 和传统的OSI网络模型的7个层次相比，TCP模型进行了进一步的封装，共有四个层次，由上至下依次如下： 应用层：向用户提供一组常用的应用程序，比如电子邮件、文件传输访问、远程登录等。远程登录TELNET使用TELNET协议提供在网络其它主机上注册的接口。TELNET会话提供了基于字符的虚拟终端。文件传输访问FTP使用FTP协议来提供网络内机器间的文件拷贝功能。 传输层：提供应用程序间的通信。其功能包括：一、格式化信息流；二、提供可靠传输。为实现后者，传输层协议规定接收端必须发回确认，并且假如分组丢失，必须重新发送。 网络层：负责相邻计算机之间的通信。其功能包括三方面：一、处理来自传输层的分组发送请求，收到请求后，将分组装入IP数据报，填充报头，选择去往信宿机的路径，然后将数据报发往适当的网络接口。二、处理输入数据报：首先检查其合法性，然后进行寻径–假如该数据报已到达信宿机，则去掉报头，将剩下部分交给适当的传输协议；假如该数据报尚未到达信宿，则转发该数据报。三、处理路径、流控、拥塞等问题。 网络接口层：这是TCP/IP软件的最低层，负责接收IP数据报并通过网络发送之，或者从网络上接收物理帧，抽出IP数据报，交给IP层。 TCP三握四挥TCP在建立固定连接时，client与server之前会有三次握手；而在释放连接时，两者之间又会有四次挥手。 TCP传送数据格式如图所示： 其中，我们需要关注的地方有，位码即tcp标志位，有6种标示：SYN(synchronous建立联机)、ACK(acknowledgement 确认)、PSH(push传送)、FIN(finish结束)、RST(reset重置)、URG(urgent紧急)，还有两个数字位：Sequence number(序号)、Acknowledge number(确认号)。 三次握手 TCP三次握手过程如下：a.第一次握手：Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。b.第二次握手：Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack number=J+1，随机产生一个值seq=K，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。c.第三次握手：Client收到确认后，检查ack number是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack number=K+1，并将该数据包发送给Server，Server检查ack number是否为K+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。 四次挥手 TCP四次挥手过程如下：a.第一次挥手：Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。b.第二次挥手：Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。c.第三次挥手：Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。d.第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1，Server进入CLOSED状态，完成四次挥手。 why三握四挥因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，”你发的FIN报文我收到了”。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。 why 2MSL按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。在Client发送出最后的ACK回复，但该ACK可能丢失。Server如果没有收到ACK，将不断重复发送FIN片段。所以Client不能立即关闭，它必须确认Server接收到了该ACK。Client会在发送出ACK之后进入到TIME_WAIT状态。Client会设置一个计时器，等待2MSL的时间。如果在该时间内再次收到FIN，那么Client会重发ACK并再次等待2MSL。所谓的2MSL是两倍的MSL(Maximum Segment Lifetime)。MSL指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。]]></content>
      <categories>
        <category>网络</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mybatis工作原理及相关]]></title>
    <url>%2Fabout-mybatis%2F</url>
    <content type="text"><![CDATA[mybatis的工作流程及关键配置 mybatis工作流程先上一张图： 由图中可以看出，mybatis最重要的两个配置之处： mybatis-config.xml–mybatis全局配置相关 mybatis-config.xml12345678910111213141516171819202122232425262728293031&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;settings&gt; &lt;setting name="cacheEnabled" value="true"/&gt; &lt;setting name="lazyLoadingEnabled" value="false"/&gt; &lt;/settings&gt; &lt;typeAliases&gt; &lt;typeAlias type="com.supertpx.dao.xxx" alias="User"/&gt; &lt;/typeAliases&gt; &lt;environments default="development"&gt; &lt;environment id="development"&gt; &lt;transactionManager type="JDBC"/&gt; &lt;!--事务管理类型--&gt; &lt;dataSource type="POOLED"&gt;&lt;!--连接池--&gt; &lt;property name="username" value="xxx"/&gt; &lt;property name="password" value="xxx"/&gt; &lt;property name="driver" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql:192.168.1.150/xxx"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource="xxxMapper.xml"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; xxxMapper.xml–mapper.xml映射文件。用于动态sql的生成和resultSet转化为对应的javaBean。 mybatis应用程序通过SqlSessionFactoryBuilder从mybatis-config.xml配置文件（也可以用Java文件配置的方式，需要添加@Configuration）中构建出SqlSessionFactory（SqlSessionFactory是线程安全的）；然后，SqlSessionFactory的实例直接开启一个SqlSession，再通过SqlSession实例获得Mapper对象并运行Mapper映射的SQL语句，完成对数据库的CRUD和事务提交，之后关闭SqlSession。 详细流程如下：1、加载mybatis全局配置文件（数据源、mapper映射文件等），解析配置文件，MyBatis基于XML配置文件生成Configuration，和一个个MappedStatement（包括了参数映射配置、动态SQL语句、结果映射配置），其对应着相应的CURD操作。2、SqlSessionFactoryBuilder通过Configuration对象生成SqlSessionFactory，用来开启SqlSession。3、SqlSession对象完成和数据库的交互：a、用户程序调用mybatis接口层api（即Mapper接口中的方法）；b、SqlSession通过调用api的Statement ID找到对应的MappedStatement对象；c、通过Executor（负责动态SQL的生成和查询缓存的维护）将MappedStatement对象进行解析，sql参数转化、动态sql拼接，生成jdbc Statement对象；d、JDBC执行sql；e、借助MappedStatement中的结果映射关系，将返回结果转化成HashMap、JavaBean等存储结构并返回。 参考文献 《深入理解mybatis原理》 MyBatis的架构设计以及实例分析]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[REDIS原理及其相关]]></title>
    <url>%2Fabout-redis%2F</url>
    <content type="text"><![CDATA[redis的工作原理以及redis各类默认策略 REDIS基本类型其实，REDIS原理是一个很泛泛而谈的话题，我们只能从redis的工作模式，redis的优缺点等方面去分析。 首先，REDIS是一个key-value的存储系统，其中，key类型为非二进制安全的字符类型（not binary safe strings），value类型则有多种，如string、list、set、hash、sorted set。 string类型：string是redis最基本的类型，是二进制安全的，如果只用string，redis可以看作加上持久化功能的memcached； list类型：list类型是一个每个元素都是string类型的双向链表，可以通过pop、push操作从链表的头部和尾部添加删除元素，list既可以用作栈，也可以用作队列； set类型：set是string类型的无序不重复集合，最多可包含2^32-1个元素，通过hash table实现； sorted set类型：string类型的有序不重复集合，与set不同的是每个元素都会关联一个double类型的score，sorted set由skip list和hash table混合实现，当添加一个元素时，该元素到score的映射被添加到hash table中，同时score到元素的映射被添加到skip list之中并按照score排序，实现有序； hash类型：是一个string类型的field和value的映射表，可以用于存储对象，占用内存少。 REDIS工作方式redis通过将整个数据库加载到内存中运行，具有极其出色的性能，同时定期通过一定的持久化策略将数据持久化到硬盘中进行保存。redis支持多种数据类型，使其可以实现多种功能，如list可用于FIFO的双向链表，可用于轻量级的高性能消息队列，set可用于tag系统，用户喜好标记等。redis的优异性能主要有以下三个原因： 纯内存操作 单线程操作，避免了频繁的上下文切换 采用了非阻塞I/O多路复用机制 redis的主要缺点是因为其运行在内存中，受到物理内存容量大小的限制，不能用于海量数据的场景。 REDIS持久化策略redis的持久化策略主要有两种，RDB模式和AOF模式，两者各有优缺。 RDB模式是将内存中数据快照备份到.rdb格式的文件中（默认为dump.rdb）,其默认快照保存配置为： 12save 900 1 #900秒内如果超过1个key被修改，则发起快照保存save 300 10 #300秒内容如超过10个key被修改，则发起快照保存 AOF模式是将每个对数据库的写命令按执行顺序添加到appendonly.aof文件中。当redis重启时，通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。有如下三种方式： 1234appendonly yes #启用aof持久化方式appendfsync always #每次收到写命令就立即强制写入磁盘，最慢的，但是保证完全的持久化，不推荐使用appendfsync everysec #每秒钟强制写入磁盘一次，在性能和持久化方面做了很好的折中，推荐appendfsync no #完全依赖os，性能最好,持久化没保证 redis的过期策略和内存淘汰机制 redis的过期策略一般是定期删除+惰性删除策略； 内存淘汰机制： 1maxmemory-policy allkeys-lru #noeviction，allkeys-lru，allkeys-random，volatile-lru，volatile-random，volatile-ttl等策略 采用redis等缓存系统需要面对的问题 redis和数据库的一致性问题。如果要求强一致性，只能不使用缓存； 缓存穿透和缓存雪崩问题。对于缓存传统，可以采用互斥锁、异步更新、布隆过滤器等策略来避免；对于缓存雪崩，可以在过期时间上加上一个随机数，避免缓存大面积失效。]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
</search>
